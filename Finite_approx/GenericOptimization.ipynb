{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "import autograd.scipy as sp\n",
    "from autograd.scipy import special\n",
    "from autograd import grad, hessian, hessian_vector_product\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "\n",
    "from scipy import optimize\n",
    "\n",
    "from valez_finite_VI_lib import initialize_parameters, generate_data, compute_elbo\n",
    "from generic_optimization_lib import unpack_params, pack_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_approx_eq(x, y, tol=1e-12):\n",
    "    return np.max(np.abs(x - y)) < tol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'autograd.scipy.special' has no attribute 'logit'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-8c588519ec60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mtau\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphi_mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphi_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitialize_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK_approx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mnu_init\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnu\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnu\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnu\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnu\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnu\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnu\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnu\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpack_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtau\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphi_mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphi_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mparams_init\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/runjing_liu/Documents/BNP/Variational_BNP_robustness/Finite_approx/generic_optimization_lib.py\u001b[0m in \u001b[0;36mpack_params\u001b[0;34m(tau, phi_mu, phi_var, nu)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpack_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtau\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphi_mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphi_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     return np.hstack([ pack_tau(tau), pack_phi_mu(phi_mu),\n\u001b[0;32m---> 31\u001b[0;31m                        pack_phi_var(phi_var), pack_nu(nu) ])\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0munpack_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK_approx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNum_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/runjing_liu/Documents/BNP/Variational_BNP_robustness/Finite_approx/generic_optimization_lib.py\u001b[0m in \u001b[0;36mpack_nu\u001b[0;34m(nu)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpack_nu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0munpack_nu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnu_packed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK_approx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'autograd.scipy.special' has no attribute 'logit'"
     ]
    }
   ],
   "source": [
    "np.random.seed(12321) # this is a seed where VI works well\n",
    "\n",
    "alpha = 10 # IBP parameter\n",
    "\n",
    "Num_samples = 2000 # sample size\n",
    "D = 2 # dimension\n",
    "# so X will be a N\\times D matrix\n",
    "\n",
    "sigma_A = 100\n",
    "\n",
    "sigma_eps = .1 # variance of noise\n",
    "\n",
    "K_inf = 3 # take to be large for a good approximation to the IBP\n",
    "\n",
    "Pi, Z, mu, A, X = generate_data(Num_samples, D, K_inf, sigma_A, sigma_eps, alpha)\n",
    "\n",
    "K_approx = deepcopy(K_inf) # variational truncation\n",
    "\n",
    "tau, nu, phi_mu, phi_var = initialize_parameters(Num_samples, D, K_approx)\n",
    "nu_init = np.round(nu * (nu >= 0.9) + nu * (nu <= 0.1)) + nu * (nu >= 0.1) * (nu <= 0.9)\n",
    "params = pack_params(deepcopy(tau), deepcopy(phi_mu), deepcopy(phi_var), deepcopy(nu))\n",
    "params_init = deepcopy(params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataSet(object):\n",
    "    def __init__(self, X, K_approx, alpha, sigma_eps, sigma_A):\n",
    "        self.X = X\n",
    "        self.K_approx = K_approx\n",
    "        self.alpha = alpha\n",
    "        self.data_shape = {'D': X.shape[1], 'N': X.shape[0] , 'K':K_approx}\n",
    "        self.sigmas = {'eps': sigma_eps, 'A': sigma_A}\n",
    "        #self.nu = np.empty((X.shape[0], K_approx))\n",
    "        \n",
    "    def wrapped_kl(self, params, verbose=False):\n",
    "        tau, phi_mu, phi_var, nu = \\\n",
    "            unpack_params(params, self.data_shape['K'], self.data_shape['D'], self.data_shape['N'])\n",
    "        elbo = compute_elbo(tau, nu, phi_mu, phi_var, self.X, self.sigmas, self.alpha)[0]\n",
    "        if verbose:\n",
    "            print -1 * elbo\n",
    "        return -1 * elbo\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4858169.677175656"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set = DataSet(X, K_approx, alpha, sigma_eps, sigma_A)\n",
    "data_set.wrapped_kl(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1708.20647253   173.71298395 -2738.82010207 ...,    35.92961572\n",
      "    60.1122894      3.58939   ]\n",
      "[ -4534516.47123467   1739212.97942215 -10179841.1094394  ...,\n",
      "  12136800.26632632  13880040.31309656   3663558.89338671]\n"
     ]
    }
   ],
   "source": [
    "get_kl_grad = grad(data_set.wrapped_kl)\n",
    "get_kl_hvp = hessian_vector_product(data_set.wrapped_kl)\n",
    "\n",
    "kl_grad = get_kl_grad(params)\n",
    "kl_hvp = get_kl_hvp(params, kl_grad)\n",
    "\n",
    "print kl_grad\n",
    "print kl_hvp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4858169.67718\n",
      "4507580.4666\n",
      "3866133.91997\n",
      "2821738.85538\n",
      "1683994.95868\n",
      "1572440.16592\n",
      "1385585.86464\n",
      "1058080.17789\n",
      "713115.448692\n",
      "673867.254049\n",
      "652979.423718\n",
      "72339145292.3\n",
      "525871.998052\n",
      "31082012003.7\n",
      "482562.78367\n",
      "714152.736789\n",
      "458236.23201\n",
      "429368.983794\n",
      "119967645.478\n",
      "408306.904637\n",
      "386204.196115\n",
      "169542542.653\n",
      "367182.946403\n",
      "343507.209254\n",
      "859416108.077\n",
      "332680.279592\n",
      "324780.309084\n",
      "307485.813777\n",
      "283213.501556\n",
      "282515.817251\n",
      "286629.181175\n",
      "275846.041605\n",
      "266747.367467\n",
      "261015.709604\n",
      "253622.764708\n",
      "1499278.5144\n",
      "245355.467608\n",
      "237294.314446\n",
      "231402.208132\n",
      "223678.672573\n",
      "220216.055715\n",
      "221615.341947\n",
      "217173.519537\n",
      "215506.618202\n",
      "211280.097351\n",
      "207516.384078\n",
      "206734.667234\n",
      "205353.683161\n",
      "204039.906242\n",
      "198806.266592\n",
      "208424.378821\n",
      "196616.541605\n",
      "195293.590273\n",
      "192710.009355\n",
      "191000.225662\n",
      "186758.43645\n",
      "185592.614838\n",
      "181473.428782\n",
      "179311.92317\n",
      "176507.956275\n",
      "171955.664224\n",
      "168771.582119\n",
      "164748.648141\n",
      "163546.096531\n",
      "160510.48432\n",
      "156485.361121\n",
      "153460.53815\n",
      "150639.49267\n",
      "153115.803271\n",
      "150547.302024\n",
      "150160.572957\n",
      "149916.470282\n",
      "149239.047513\n",
      "147802.073142\n",
      "146965.809769\n",
      "146645.488701\n",
      "144907.85863\n",
      "143876.749676\n",
      "142400.87964\n",
      "141252.792456\n",
      "140278.776473\n",
      "137099.590059\n",
      "154694.140503\n",
      "144148.991359\n",
      "136342.774695\n",
      "136070.482323\n",
      "135657.652193\n",
      "135055.229504\n",
      "134258.030254\n",
      "132989.165165\n",
      "132629.391878\n",
      "130564.09875\n",
      "130097.135155\n",
      "130568.663408\n",
      "129589.883886\n",
      "128643.353602\n",
      "127539.526886\n",
      "127380.81951\n",
      "127040.028416\n",
      "126638.033052\n",
      "125521.28467\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 125521.284670\n",
      "         Iterations: 100\n",
      "         Function evaluations: 101\n",
      "         Gradient evaluations: 85\n",
      "         Hessian evaluations: 0\n"
     ]
    }
   ],
   "source": [
    "vb_opt = optimize.minimize(\n",
    "    lambda params: data_set.wrapped_kl(params, verbose=True),\n",
    "    params_init, method='trust-ncg', jac=get_kl_grad, hessp=get_kl_hvp,\n",
    "    tol=1e-6, options={'maxiter': 100, 'disp': True, 'gtol': 1e-6 })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7.27434354 -2.006652  ]\n",
      " [ 8.3221905  -1.20240182]\n",
      " [ 8.55562752 -0.59554079]]\n",
      "[[ 13.17491681  -7.83796064]\n",
      " [  0.1543092    0.97045299]\n",
      " [ 10.94654306   3.54649255]]\n"
     ]
    }
   ],
   "source": [
    "tau, phi_mu, phi_var, nu = unpack_params(vb_opt.x, D=D, K_approx=K_approx, Num_samples=Num_samples)\n",
    "print phi_mu.transpose()\n",
    "print A"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
