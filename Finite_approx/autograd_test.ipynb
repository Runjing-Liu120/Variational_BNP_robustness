{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Testing updates with autograd\n",
    "\n",
    "from autograd import grad\n",
    "import autograd.numpy as np\n",
    "import autograd.scipy as sp\n",
    "from copy import deepcopy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement log likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def exp_log_likelihood(nu_moment, phi_moment1, phi_moment2, \\\n",
    "                       E_log_pi1, E_log_pi2, Data_shape, sigmas, X, alpha):\n",
    "    \n",
    "    sigma_eps = sigmas['eps']\n",
    "    sigma_A = sigmas['A']\n",
    "    D = Data_shape['D']\n",
    "    N = Data_shape['N']\n",
    "    K = Data_shape['K']\n",
    "\n",
    "    beta_lh = (alpha/K - 1.)*np.sum(E_log_pi1) \n",
    "    bern_lh = np.sum(np.dot(nu_moment[n,:], E_log_pi1) \\\n",
    "                            + np.dot(1.-nu_moment[n,:], E_log_pi2) for n in range(N))\n",
    "    Normal_A = -1/(2.*sigma_A) * np.sum(phi_moment2)\n",
    "    \n",
    "    Normal_X_sum = 0\n",
    "    ## compute the data likelihood term\n",
    "    for n in range(N): \n",
    "        dum1 = 2.*np.sum(np.sum(nu_moment[n,i] * nu_moment[n,j] * np.dot(phi_moment1[:,i],phi_moment1[:,j]) \\\n",
    "                                for i in range(j)) for j in range(K))\n",
    "        dum2 = np.dot(nu_moment[n,:] , phi_moment2 )\n",
    "        \n",
    "        dum3 = -2. * np.dot(X[n,:], np.dot(phi_moment1, nu_moment[n,:]))\n",
    "        \n",
    "        # dum4 = np.dot(X[n,:], X[n,:])\n",
    "        Normal_X_sum += dum1 + dum2 + dum3\n",
    "        \n",
    "    Normal_X = -1/(2*sigma_eps)*Normal_X_sum\n",
    "    \n",
    "    y = beta_lh + bern_lh + Normal_A + Normal_X\n",
    "    return(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nu updates\n",
    "for simplicity of comparision, this function will return the canonical paramter, log(p/1-p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nu_updates(tau, nu, phi_mu, phi_var, X, sigmas, Data_shape): \n",
    "    \n",
    "    s_eps = sigmas['eps']\n",
    "    K = Data_shape['K']\n",
    "    N = Data_shape['N']\n",
    "    D = Data_shape['D']\n",
    "    script_V = np.zeros([N, K])\n",
    "    \n",
    "    for n in range(N):\n",
    "        for k in range(K):\n",
    "                            \n",
    "            nu_term1 = sp.special.digamma(tau[k,0]) - sp.special.digamma(tau[k,1])  \n",
    "            \n",
    "            nu_term2 = (1. / (2. * s_eps)) * (phi_var[k]*D + np.dot(phi_mu[:,k], phi_mu[:,k]))\n",
    "            \n",
    "            \n",
    "            nu_term3 = (1./s_eps) * np.dot(phi_mu[:, k], X[n, :] - np.dot(phi_mu, nu[n, :]) + nu[n,k] * phi_mu[:, k])\n",
    "            \n",
    "            #if k==4 and n==3:\n",
    "            #    print(nu_term2,nu_term3)\n",
    "\n",
    "            #explit calculation of Term3\n",
    "            dum = 0\n",
    "            for l in range(K):\n",
    "                if (l != k):\n",
    "                    dum += nu[n,l] * phi_mu[:,l]\n",
    "        \n",
    "            nu_term3_alt = (1 / s_eps) * np.dot(phi_mu[:,k], X[n,:] - dum)\n",
    "            \n",
    "            if np.abs(nu_term3 - nu_term3_alt)>10**(-10):\n",
    "                print(nu_term3-nu_term3_alt)\n",
    "                print('calculation of nu_term3 is off')\n",
    "                input('paused')\n",
    "                \n",
    "                \n",
    "            #if k==0 and n==0:\n",
    "            #    print(nu_term1, nu_term2, nu_term3)\n",
    "                \n",
    "            script_V[n,k] = nu_term1 - nu_term2 + nu_term3\n",
    "    \n",
    "    return(script_V)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tau updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tau_updates(tau, nu, alpha, Data_shape): \n",
    "    K = Data_shape['K']\n",
    "    N = Data_shape['N']\n",
    "\n",
    "    tau[:,0] = alpha/K + np.sum(nu,0)\n",
    "    tau[:,1] = N  + 1 - np.sum(nu,0)\n",
    "    \n",
    "    return(tau)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# phi updates\n",
    "note that in order to compare with autodiff, we didn't use the \"freshest\" updates when cycling through K \n",
    "(see the deepcopy command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def phi_updates(nu, phi_mu, phi_var, X, sigmas, Data_shape):\n",
    "    \n",
    "    phi_mu_copy = deepcopy(phi_mu)\n",
    "    phi_var_copy = deepcopy(phi_var)\n",
    "    \n",
    "\n",
    "    s_eps = sigmas['eps']\n",
    "    s_A = sigmas['A']\n",
    "    D = Data_shape['D']\n",
    "    N = Data_shape['N']\n",
    "    K = Data_shape['K']\n",
    "    \n",
    "    for k in range(K):\n",
    "        phi_var[k] = (1/s_A + np.sum(nu[:, k]) / s_eps)**(-1) \n",
    "               \n",
    "        phi_summation = 0\n",
    "        phi_summation_alt = 0\n",
    "        for n in range(N):\n",
    "            phi_dum1 = X[n, :] - np.dot(phi_mu_copy, nu[n, :]) + nu[n, k] * phi_mu_copy[:, k]\n",
    "            phi_summation += nu[n,k]*phi_dum1\n",
    "        \n",
    "            dum1 = 0\n",
    "            for l in range(K):\n",
    "                if (l != k):\n",
    "                    dum1 += nu[n,l] * phi_mu_copy[:,l]\n",
    "            phi_summation_alt += nu[n,k] * (X[n,:] - dum1)\n",
    "            \n",
    "            if np.linalg.norm(phi_summation - phi_summation_alt)>=10**(-10):\n",
    "                print('error in phi_mu updates')\n",
    "            \n",
    "        phi_mu[:,k] = (1 / s_eps) * phi_summation * (1/s_A + np.sum(nu[:, k]) / s_eps)**(-1)\n",
    "                 \n",
    "    return(phi_mu, phi_var)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Num_samples = 500 # sample size\n",
    "D = 2 # dimension\n",
    "# so X will be a n\\times D matrix\n",
    "\n",
    "K_inf = 3 # take to be large for a good approximation to the IBP\n",
    "K_approx = deepcopy(K_inf)\n",
    "\n",
    "alpha = 2 # IBP parameter\n",
    "Pi = np.zeros(K_inf)\n",
    "Z = np.zeros([Num_samples,K_inf])\n",
    "\n",
    "# Parameters to draw A from MVN\n",
    "mu = np.zeros(D)\n",
    "sigma_A = 100\n",
    "\n",
    "sigma_eps = 1 # variance of noise\n",
    "\n",
    "# Draw Z from truncated stick breaking process\n",
    "for k in range(K_inf):\n",
    "    Pi[k] = np.random.beta(alpha/K_inf,1)\n",
    "    for n in range(Num_samples):\n",
    "        Z[n,k] = np.random.binomial(1,Pi[k])\n",
    "\n",
    "# Draw A from multivariate normal\n",
    "A = np.random.multivariate_normal(mu, sigma_A*np.identity(D), K_inf)\n",
    "# A = np.array([[10,10], [-10,10]])\n",
    "\n",
    "# draw noise\n",
    "epsilon = np.random.multivariate_normal(np.zeros(D), sigma_eps*np.identity(D), Num_samples)\n",
    "\n",
    "# the observed data\n",
    "X = np.dot(Z,A) + epsilon\n",
    "\n",
    "\n",
    "Data_shape = {'D':D, 'N': Num_samples , 'K':K_approx}\n",
    "sigmas = {'eps': sigma_eps, 'A': sigma_A}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Nu Updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result from cavi: \n",
      " [[  5.66038268   8.37767961   4.2027485 ]\n",
      " [  5.29226423   7.08473386   2.66879137]\n",
      " [  7.15762849  13.43727366  14.19137653]\n",
      " [  6.26733998  13.06164459  12.77718154]\n",
      " [  4.44340402   5.32666842   1.38634324]]\n",
      "Result from autodiff: \n",
      " [[  5.66038268   8.37767961   4.2027485 ]\n",
      " [  5.29226423   7.08473386   2.66879137]\n",
      " [  7.15762849  13.43727366  14.19137653]\n",
      " [  6.26733998  13.06164459  12.77718154]\n",
      " [  4.44340402   5.32666842   1.38634324]]\n",
      "l1 distance between results: \n",
      " 1.85798598729e-12\n"
     ]
    }
   ],
   "source": [
    "# initialization for cavi updates\n",
    "tau = np.random.uniform(10,100,[K_approx,2])\n",
    "nu = np.random.uniform(0,1,[Num_samples,K_approx])\n",
    "\n",
    "phi_mu = np.random.normal(0,1,[D,K_approx])\n",
    "phi_var = np.ones(K_approx)\n",
    "\n",
    "# autodiff \n",
    "d_exp_log_LH = grad(exp_log_likelihood, 0)\n",
    "\n",
    "# compute required moments\n",
    "nu_moment = deepcopy(nu)\n",
    "phi_moment1 = deepcopy(phi_mu)\n",
    "phi_moment2 = np.diag(np.dot(phi_mu.T, phi_mu) + D * phi_var)\n",
    "E_log_pi1 = sp.special.digamma(tau[:,0]) - sp.special.digamma(tau[:,0] + tau[:,1]) \n",
    "E_log_pi2 = sp.special.digamma(tau[:,1]) - sp.special.digamma(tau[:,0] + tau[:,1]) \n",
    "\n",
    "# compute updates\n",
    "script_V_AG = d_exp_log_LH(nu_moment, phi_moment1, phi_moment2, \\\n",
    "                       E_log_pi1, E_log_pi2, Data_shape, sigmas, X, alpha)\n",
    "script_V = nu_updates(tau, nu, phi_mu, phi_var, X, sigmas, Data_shape)\n",
    "\n",
    "print('Result from cavi: \\n', script_V[0:5,:])\n",
    "print('Result from autodiff: \\n', script_V_AG[0:5,:])\n",
    "print('l1 distance between results: \\n', np.sum(np.abs(script_V - script_V_AG)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test tau updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results from cavi update: \n",
      " [[ 256.82907802  257.2111046   250.4530291 ]\n",
      " [ 244.83758865  244.45556206  251.21363757]]\n",
      "results from autograd: \n",
      "[ 256.82907802  257.2111046   250.4530291 ]\n",
      "[ 244.83758865  244.45556206  251.21363757]\n"
     ]
    }
   ],
   "source": [
    "# initialization for cavi updates\n",
    "tau = np.random.uniform(10,100,[K_approx,2])\n",
    "nu = np.random.uniform(0,1,[Num_samples,K_approx])\n",
    "\n",
    "phi_mu = np.random.normal(0,1,[D,K_approx])\n",
    "phi_var = np.ones(K_approx)\n",
    "\n",
    "# calling autodiff\n",
    "d_tau1 = grad(exp_log_likelihood, 3)\n",
    "d_tau2 = grad(exp_log_likelihood, 4)\n",
    "\n",
    "# computing moments\n",
    "nu_moment = deepcopy(nu)\n",
    "phi_moment1 = deepcopy(phi_mu)\n",
    "phi_moment2 = np.diag(np.dot(phi_mu.T, phi_mu) + D * phi_var)\n",
    "E_log_pi1 = sp.special.digamma(tau[:,0]) - sp.special.digamma(tau[:,0] + tau[:,1]) \n",
    "E_log_pi2 = sp.special.digamma(tau[:,1]) - sp.special.digamma(tau[:,0] + tau[:,1]) \n",
    "\n",
    "# computing updates\n",
    "tau1_AG = d_tau1(nu_moment, phi_moment1, phi_moment2, \\\n",
    "                       E_log_pi1, E_log_pi2, Data_shape, sigmas, X, alpha) + 1\n",
    "tau2_AG = d_tau2(nu_moment, phi_moment1, phi_moment2, \\\n",
    "                       E_log_pi1, E_log_pi2, Data_shape, sigmas, X, alpha) + 1\n",
    "\n",
    "tau_cavi = tau_updates(tau, nu, alpha, Data_shape)\n",
    "\n",
    "print('results from cavi update: \\n', tau_cavi.T)\n",
    "print('results from autograd: ')\n",
    "print(tau1_AG)\n",
    "print(tau2_AG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing phi updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean computed by autodiff: \n",
      " [[-9.53047836 -9.04732071 -8.49000704]\n",
      " [ 8.02669571  8.33481607  8.50617987]]\n",
      "mean computed by cavi: \n",
      " [[-9.53047836 -9.04732071 -8.49000704]\n",
      " [ 8.02669571  8.33481607  8.50617987]]\n",
      "variance computed by autodiff:  [ 0.00406788  0.00388216  0.00400152]\n",
      "variance computed by cavi    :  [ 0.00406788  0.00388216  0.00400152]\n"
     ]
    }
   ],
   "source": [
    "# initialization for cavi updates\n",
    "tau = np.random.uniform(10,100,[K_approx,2])\n",
    "nu = np.random.uniform(0,1,[Num_samples,K_approx])\n",
    "\n",
    "phi_mu = np.random.normal(0,1,[D,K_approx])\n",
    "phi_var = np.ones(K_approx)\n",
    "\n",
    "# calling autodiff\n",
    "d_phi1  = grad(exp_log_likelihood, 1)\n",
    "d_phi2 = grad(exp_log_likelihood, 2)\n",
    "\n",
    "# compute moments\n",
    "nu_moment = deepcopy(nu)\n",
    "phi_moment1 = deepcopy(phi_mu)\n",
    "phi_moment2 = np.diag(np.dot(phi_mu.T, phi_mu) + D * phi_var)\n",
    "\n",
    "E_log_pi1 = sp.special.digamma(tau[:,0]) - sp.special.digamma(tau[:,0] + tau[:,1]) \n",
    "E_log_pi2 = sp.special.digamma(tau[:,1]) - sp.special.digamma(tau[:,0] + tau[:,1]) \n",
    "\n",
    "# compute updates\n",
    "phi1_AG = d_phi1(nu_moment, phi_moment1, phi_moment2, \\\n",
    "                       E_log_pi1, E_log_pi2, Data_shape, sigmas, X, alpha) \n",
    "phi2_AG = d_phi2(nu_moment, phi_moment1, phi_moment2, \\\n",
    "                       E_log_pi1, E_log_pi2, Data_shape, sigmas, X, alpha) \n",
    "\n",
    "# convert to standard parametrization\n",
    "phi_var_AG = -1/(2.*phi2_AG)\n",
    "phi_mu_AG = np.dot(phi1_AG, np.diag(phi_var_AG))\n",
    "\n",
    "# cavi update\n",
    "[phi_mu_cavi, phi_var_cavi] = phi_updates(nu, phi_mu, phi_var, X, sigmas, Data_shape)\n",
    "\n",
    "print('mean computed by autodiff: \\n', phi_mu_AG)\n",
    "print('mean computed by cavi: \\n', phi_mu_cavi)\n",
    "print('variance computed by autodiff: ', phi_var_AG)\n",
    "print('variance computed by cavi    : ', phi_var_cavi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
