{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collapsed Gibbs sampler for the finite IBP approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "\n",
    "import VI_algorithms_lib\n",
    "import valez_finite_VI_lib\n",
    "from gibbs_sampler_lib import CollapsedGibbsSampler, display_results_Gibbs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# np.random.seed(5365) this seed works pretty well\n",
    "np.random.seed(6874)\n",
    "\n",
    "Num_samples = 500 # sample size\n",
    "D = 2 # dimension\n",
    "# so X will be a N\\times D matrix\n",
    "\n",
    "K_inf = 3 # take to be large for a good approximation to the IBP\n",
    "\n",
    "alpha = 10 # IBP parameter\n",
    "\n",
    "# Parameters to draw A from MVN\n",
    "sigma_eps = .1 # variance of noise\n",
    "sigma_A = 100\n",
    "\n",
    "# generate data\n",
    "Pi, Z, mu, A, X = valez_finite_VI_lib.generate_data(Num_samples, D, K_inf, sigma_A, sigma_eps, alpha)\n",
    "\n",
    "K_approx = deepcopy(K_inf) # variational truncation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run collapsed Gibbs sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                               \r",
      "\r",
      "N/A% (0 of 600) |                        | Elapsed Time: 0:00:00 ETA:  --:--:--"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19% (116 of 600) |####                    | Elapsed Time: 0:00:58 ETA: 0:04:00"
     ]
    }
   ],
   "source": [
    "collapsed_GS = CollapsedGibbsSampler(X, K_approx, alpha, sigma_eps, sigma_A)\n",
    "\n",
    "collapsed_GS.sample(100, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "post_mean_Z = np.mean(collapsed_GS.z_draws, 0)\n",
    "#post_mean_Z = collapsed_GS.z\n",
    "tmp = np.dot(post_mean_Z.T, post_mean_Z) + sigma_eps/sigma_A * np.eye(K_approx)\n",
    "mean_A = np.dot(np.linalg.solve(tmp, post_mean_Z.T), X)\n",
    "\n",
    "display_results_Gibbs(X, Z, post_mean_Z, mean_A, A, manual_perm = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run VB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "nu_updates() got an unexpected keyword argument 'anneal_temp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-eb12e0abf8e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_restart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mVI_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mre_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# re initialize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;34m[\u001b[0m\u001b[0mtau_tmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnu_tmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphi_mu_tmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphi_var_tmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melbo\u001b[0m\u001b[0;34m]\u001b[0m         \u001b[0;34m=\u001b[0m \u001b[0mVI_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cavi_anneal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# run cavi + annealing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0melbo_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melbo_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melbo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/runjing_liu/Documents/BNP/Variational_BNP_robustness/finite_approx/VI_algorithms_lib.py\u001b[0m in \u001b[0;36mrun_cavi_anneal\u001b[0;34m(self, rho, max_iter, tol, verbose)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             cavi_anneal_update(self.tau, self.nu, self.phi_mu, self.phi_var, \\\n\u001b[0;32m--> 229\u001b[0;31m                 self.x, self.alpha, self.sigmas, anneal_temp, step_size)\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m             elbo = np.append(elbo, vi.compute_elbo(\\\n",
      "\u001b[0;32m/home/runjing_liu/Documents/BNP/Variational_BNP_robustness/finite_approx/VI_algorithms_lib.py\u001b[0m in \u001b[0;36mcavi_anneal_update\u001b[0;34m(tau, nu, phi_mu, phi_var, X, alpha, sigmas, anneal_temp, step_size, stochastic, random_seed)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 vi.nu_updates(tau, nu, phi_mu, phi_var, X, sigmas, n, k, \\\n\u001b[0;32m---> 31\u001b[0;31m                     digamma_tau, anneal_temp = anneal_temp)\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: nu_updates() got an unexpected keyword argument 'anneal_temp'"
     ]
    }
   ],
   "source": [
    "VI_instance = VI_algorithms_lib.VI_algorithms(X, K_approx, alpha, sigma_eps, sigma_A)\n",
    "\n",
    "n_restart = 20\n",
    "elbo_end = np.array([])\n",
    "\n",
    "for i in range(n_restart): \n",
    "    VI_instance.re_init() # re initialize\n",
    "    [tau_tmp, nu_tmp, phi_mu_tmp, phi_var_tmp, elbo] \\\n",
    "        = VI_instance.run_cavi_anneal(max_iter=500, tol=1e-6, verbose = False) # run cavi + annealing\n",
    "        \n",
    "    elbo_end = np.append(elbo_end, elbo[-1])\n",
    "    \n",
    "    # see if posterior predictive is better than all previous ones\n",
    "    if (i == 0) or np.all(elbo_end[i] > elbo_end[:i]): \n",
    "        tau = deepcopy(tau_tmp)\n",
    "        nu = deepcopy(nu_tmp)\n",
    "        phi_mu = deepcopy(phi_mu_tmp)\n",
    "        phi_var = deepcopy(phi_var_tmp)\n",
    "    \n",
    "    \n",
    "print('max elbo: ', np.max(elbo_end))\n",
    "print('average elbo', np.mean(elbo_end))\n",
    "\n",
    "valez_finite_VI_lib.display_results(elbo, tau, nu, phi_mu, phi_var, X, Pi, Z, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compare results\n",
    "VI_pred_X = np.dot(nu, phi_mu.T)\n",
    "Gibbs_pred_X = np.dot(Z_Gibbs, mean_A)\n",
    "\n",
    "for col in range(D):\n",
    "    plt.clf()\n",
    "    plt.plot(VI_pred_X[:, col], Gibbs_pred_X[:, col], 'ko')\n",
    "    diag = np.linspace(np.min(VI_pred_X[:,col]),np.max(VI_pred_X[:,col]))\n",
    "    plt.plot(diag,diag)\n",
    "    \n",
    "    plt.title('Posterior predictive, VB vs Gibbs, column' + str(col))\n",
    "    plt.xlabel('VI_pred_X')\n",
    "    plt.ylabel('Gibbs_pred_X')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_fun(x): \n",
    "    x[0] = x[0]+1 \n",
    "    y = x ** 2\n",
    "    return(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.array([2,3])\n",
    "test_fun(x)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# posterior covariances of mu\n",
    "# compare against truth\n",
    "# rank 1 updates\n",
    "# bigger data\n",
    "# beta parameter type"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
